<!doctype html><html lang=ko><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-Q6LJX3GCJZ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-Q6LJX3GCJZ');</script><title>[REVIEW] DRQ: Dynamic Region-based Quantization for Deep Neural Network Acceleration ::
Junhyuk So's Blog</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="[DRAFT]
DRQ: Dynamic Region-based Quantization for Deep Neural Network Acceleration
Zhuoran Song1, Bangqi Fu1, Feiyang Wu1, Zhaoming Jiang1, Li Jiang1, Naifeng Jing1*, Xiaoyao Liang1,2 1 Shanghai Jiao Tong University, China, 2 Biren Research, China
핵심  Sentivity Region을 찾고, 그 부분만 High Precision 으로 Quantization Unsensitivity Region 은 Low Precision으로 Quantization. Sensitivity Region은 Inference machine에서 Runtime에 찾음 - &amp;ldquo;Dynamic!&amp;rdquo; 이에 따른 가속기 설계  Sensitivity Region 찾기 Input Feature Map에서"><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://junhyukso.github.io/post/drq/><link rel=stylesheet href=https://junhyukso.github.io/assets/style.css><link rel=stylesheet href=https://junhyukso.github.io/style.css><link rel=apple-touch-icon-precomposed sizes=144x144 href=https://junhyukso.github.io/img/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=https://junhyukso.github.io/img/favicon.png><link href=https://junhyukso.github.io/assets/fonts/Inter-Italic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-Regular.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-Medium.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-MediumItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-Bold.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-BoldItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><meta name=twitter:card content="summary"><meta name=twitter:title content="[REVIEW] DRQ: Dynamic Region-based Quantization for Deep Neural Network Acceleration"><meta name=twitter:description content="ISCA20에 발표된 DRQ논문의 리뷰입니다. DRQ는 Input Image에 따라 Dynamic 하게 Quantization을 적용합니다."><meta property="og:title" content="[REVIEW] DRQ: Dynamic Region-based Quantization for Deep Neural Network Acceleration"><meta property="og:description" content="ISCA20에 발표된 DRQ논문의 리뷰입니다. DRQ는 Input Image에 따라 Dynamic 하게 Quantization을 적용합니다."><meta property="og:type" content="article"><meta property="og:url" content="https://junhyukso.github.io/post/drq/"><meta property="article:published_time" content="2020-12-01T01:56:20+09:00"><meta property="article:modified_time" content="2020-12-01T01:56:20+09:00"><meta property="og:site_name" content="Junhyuk So's Blog"></head><body><div class=container><header class=header><span class=header__inner><a href=/ class=logo style=text-decoration:none><span class=logo__mark><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg></span><span class=logo__text>Junhyuk So's Blog</span>
<span class=logo__cursor></span></a><span class=header__right><nav class=menu><ul class="menu__inner menu__inner--desktop"><li><a href=/about>About</a></li><li><a href=/archive>Archive</a></li><li><a href=/tags>Tags</a></li></ul><ul class="menu__inner menu__inner--mobile"><li><a href=/about>About</a></li><li><a href=/archive>Archive</a></li><li><a href=/tags>Tags</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></span><span class=theme-toggle><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M22 41C32.4934 41 41 32.4934 41 22 41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span></span></span></header><div class=content><div class=post><h1 class=post-title>[REVIEW] DRQ: Dynamic Region-based Quantization for Deep Neural Network Acceleration</h1><div class=post-meta><span class=post-date>2020-12-01</span>
<span class=post-read-time>— 3 min read</span></div><span class=post-tags><a href=https://junhyukso.github.io/tags/review/>#Review</a>&nbsp;
<a href=https://junhyukso.github.io/tags/deeplearning/>#DeepLearning</a>&nbsp;
<a href=https://junhyukso.github.io/tags/efficient-dl/>#Efficient DL</a>&nbsp;
<a href=https://junhyukso.github.io/tags/quantization/>#Quantization</a>&nbsp;</span><figure class=post-cover><img src=https://junhyukso.github.io/img/post/DRQ/cover.png alt="[REVIEW] DRQ: Dynamic Region-based Quantization for Deep Neural Network Acceleration"></figure><div class=post-content><h2>Table of Contents</h2><aside class=table-of-contents><nav id=TableOfContents><ul><li><a href=#핵심>핵심</a></li><li><a href=#sensitivity-region-찾기>Sensitivity Region 찾기</a><ul><li><a href=#sensitivity-values>Sensitivity Values</a></li><li><a href=#sensitive-region>Sensitive Region</a></li></ul></li><li><a href=#sensitivity-region-찾기-알고리즘>Sensitivity Region 찾기 알고리즘</a></li><li><a href=#architecture-for-drq>Architecture for DRQ</a></li><li><a href=#experimental-results>Experimental Results</a></li></ul></nav></aside><p>[DRAFT]</p><p>DRQ: Dynamic Region-based Quantization for
Deep Neural Network Acceleration</p><p>Zhuoran Song1, Bangqi Fu1, Feiyang Wu1, Zhaoming Jiang1, Li Jiang1, Naifeng Jing1*, Xiaoyao Liang1,2
1 Shanghai Jiao Tong University, China, 2 Biren Research, China</p><h2 id=핵심>핵심</h2><ul><li>Sentivity Region을 찾고, 그 부분만 High Precision 으로 Quantization</li><li>Unsensitivity Region 은 Low Precision으로 Quantization.</li><li>Sensitivity Region은 Inference machine에서 Runtime에 찾음 - &ldquo;Dynamic!&rdquo;</li><li>이에 따른 가속기 설계</li></ul><h2 id=sensitivity-region-찾기>Sensitivity Region 찾기</h2><p>Input Feature Map에서</p><ul><li>어떤 픽셀들이 NN Acc와 직결되는가?</li><li>어떻게 찾는가? 분포는 어떻게 되는가?</li></ul><h3 id=sensitivity-values>Sensitivity Values</h3><p><img src=/img/post/DRQ/sensitivity_values.png alt="Sensitive values"></p><p>우선 Input Featrue Map을 세 그룹으로 나눕니다. 나누는 기준은 Input의 Magnitude를 기준으로,</p><p>상위 20%, 20~80%, 80% 입니다.</p><p>그리고 각각의 그룹에 노이즈를 적용합니다. 예를들어, 상위 20%에만 노이즈를 줬다면 TFF</p><p>상위 20%,20~80%에만 줬다면 TTF입니다.</p><p><strong>Observation from experiment</strong></p><ul><li>TFF가 FTF,FFT보다 Drop이 급격함.</li><li>TFF ,TFT,TTF,TTT가 거의 일정. 즉, 상위20%그룹의 영향이 가장 큼.</li><li>FFT는 큰 노이즈를 허용함.</li><li>Imagenet이 Cifar10보다 좀 더 Noise에 민감.</li></ul><p>즉, 어떤 Input들이 다른 Impact를 가짐을 알수있습니다.</p><h3 id=sensitive-region>Sensitive Region</h3><p><img src=/img/post/DRQ/sensitivity_region.png alt="Sensitive Region"></p><p>우선 저자들은 Visualize 쉬운 구조를 위해, LeNet5에 MNIST데이터셋에 대해 실험을 수행했습니다.</p><p>Fig. 3은 LeNet5에 3이란 이미지를 넣었을때, 처음 3 레이어를 나타낸 그림입니다.</p><p>결과적으로, Magnitude가 큰 Group - Segment 0은 무작위적으로 분포하지 않고, 집합하는 경향이 있음을 알 수 있습니다. Segment 2는 중요하지 않은 부분에 넓게 분포함을 확인할 수 있습니다.</p><p>그렇다면, IPF의 2차원평면을 x*y의 Patch로 나눠서 , Sensitive/ Insensitive한 Patch를 구분합니다.</p><h2 id=sensitivity-region-찾기-알고리즘>Sensitivity Region 찾기 알고리즘</h2><ul><li>Runtime에 어떻게 Sensitive Region을 구분할 것인가? 그것도 빠르고 HW Friendly하게?
Weight는 Offline으로 되지만 Input은 Online으로 되어야 한다.</li><li>어떻게 Efficient Input Sparsity Aware Convolution을 할것인가? Insensitive Region의 위치는 계속 달라질 수 있다&mldr;</li></ul><p><strong>Algorithm Overview</strong></p><p><img src=/img/post/DRQ/DRQ_algo_overview.png alt="DRQ Overview"></p><ol><li>Sensitive Region Predictor</li></ol><p>Mean Filtering 후 Step Activiation Function 통과 시켜 Binary Mask 생성 → Section III-B for detail.</p><ul><li>h*w사이즈의 IFM을 받아서, 우선 FP32→INT8로 Quantize 합니다.</li><li>IFM을 여러개의 x*y 개의 region으로 분할합니다.</li><li>Mean Filtering 합니다</li><li>이를 <strong>Predifiend Threshold Activation에 통과 시킵니다.</strong></li><li>이를 통해 Binary Mask를 만듭니다. Binary Mask의 dimension은 (h<em>w)/(x</em>y) 입니다.</li><li></li></ul><ol start=2><li>Mixed Precision Convolution</li></ol><p><img src=/img/post/DRQ/mixed_precision_conv.png alt="Mixed Precision Convolution"></p><p>Sensitive/Insensitive Region에 대해 다른 Precision(INT8/INT4)로 Conv를 수행합니다. → Senction III-C</p><ul><li>우선 Kernel Weights들은 INT8로 Qunatize하여 DRAM에 저장합니다.</li><li>Sensitive Region과 연산할때는, 일반 INT8 Convolution을 사용합니다.</li><li>INSensitive Region으로 연산할때는 Input이 INT4로 DRAM에 저장됩니다. Convolution시는, Weights를 바로 INT4범위로 Clipping 해서 INT4 Conv를 수행합니다.</li><li>더 복잡한 구현설명은 Section IV에 설명됩니다.</li></ul><p><strong>Design Space Exploration</strong></p><p>두가지 DSE요소가 있습니다.</p><p>첫째는 Threshold 입니다.</p><p>Threshold가 클수록 당연히 속도향상이 클것이지만(Insensitive Region이 많아지므로), ACC drop이 클것입니다.</p><p>두번째는 Region(x*y)의 크기 입니다.</p><p>Region이 작을 수록 세세한 Input을 보는것이므로 정확도에의 영향이 작겠지만, 속도에는 악 영향일것입니다. 또한 Region의 크기는 HW Friendly해야합니다.</p><p>해결방법은 Retrain-Finetune 입니다.</p><ul><li>우선 IFM의 Distribution을 뽑습니다.</li><li>Threshold와 Region Size를 적당히 큰값으로 작습니다.</li><li>이러한 Threshold와 Region Size를 적용한 Forward Pass를 Mixed Precision으로 수행합니다.</li><li>Backward Pass는 Full Precision으로 진행합니다.</li><li>이를 정확도가 수렴할때까지 진행합니다.</li><li>최종 정확도가 목표한 정확도면 중지하고, 그렇지 않으면 Threshol와 Region Size를 더 줄여(1/2) 다시 진행합니다.</li><li>위의 과정은 몇 Iter 만에 끝나기때문에 빠르게 가능합니다.</li></ul><p><img src=/img/post/DRQ/result_th_reg.png alt="real threshold and region size"></p><h2 id=architecture-for-drq>Architecture for DRQ</h2><p>이부분은 일단 HW에 대한 지식이 부족하여 스킵합니다.</p><h2 id=experimental-results>Experimental Results</h2><p>Accuracy</p><p><img src=/img/post/DRQ/result_acc.png alt="result acc"></p><p>Performance</p><p><img src=/img/post/DRQ/result_time.png alt="result time"></p><p>Energy Consumption</p><p><img src=/img/post/DRQ/result_power.png alt="result Energy"></p><p>가장 빠르고, 저전력이면서 정확도도 떨어지지 않음!</p></div><div class=pagination><div class=pagination__title><span class=pagination__title-h>Read other posts</span><hr></div><div class=pagination__buttons><span class="button previous"><a href=https://junhyukso.github.io/post/tf_keras_layer_wrapper/><span class=button__icon>←</span>
<span class=button__text>[TF2.0]keras Layer Wrapping 하기</span></a></span>
<span class="button next"><a href=https://junhyukso.github.io/post/install_tor_on_ubuntu/><span class=button__text>Ubuntu에서 Tor 사용하기</span>
<span class=button__icon>→</span></a></span></div></div><script src=https://utteranc.es/client.js repo=junhyukso/junhyukso.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div><footer class=footer><div class=footer__inner><a href=/ class=logo style=text-decoration:none><span class=logo__mark><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg></span><span class=logo__text>Junhyuk So's Blog</span>
<span class=logo__cursor></span></a><div class=copyright><span>© 2020 Powered by
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a></span>
<span>Theme created by
<a href=https://twitter.com/panr target=_blank rel=noopener>panr</a></span></div></div></footer><script src=https://junhyukso.github.io/assets/main.js></script><script src=https://junhyukso.github.io/assets/prism.js></script></div></body></html>