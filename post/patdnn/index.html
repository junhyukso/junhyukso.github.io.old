<!doctype html><html lang=ko><head><title>[REVIEW]PatDNN: Achieving Real-Time DNN Execution on Mobile Devices with Pattern-based Weight Pruning ::
Junhyuk So's Blog</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Pruning Pruning은 딥러닝 모델에서 특정 Weight들을 0으로만들거나, 아예 제거시키는 기법입니다. 이렇게 하게되면 정확도를 조금만 떨어트리거나 혹은 심지어 향상시키면서, 모델의 사이즈나 추론속도를 빠르게 만들 수 있습니다.
Unstructured Pruning Unstructured Pruning이란 Fig 2.(a)와 같이 element-wise하게 Pruning 하는 방법입니다.
이러면 낮은 Accuracy Drop과 **상대적으로 높은 Pruning Rate(Sparsity)**는 얻을 수 있으나, 매우 높은 Sparsity가 아닌 이상 추론속도를 향상시키기가 실질적으로 어렵습니다.
왜냐하면 딥러닝 연산은 대부분 행렬곱 연산으로 수행되는데, Sparse 행렬곱의 경우는 **Sparsity가 약 8~90%**정도는 되어야만 가속 효과가 나타나기 때문입니다."><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://junhyukso.github.io/post/patdnn/><script async src="https://www.googletagmanager.com/gtag/js?id=G-Q6LJX3GCJZ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-Q6LJX3GCJZ');</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]}};</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><link rel=stylesheet href=https://junhyukso.github.io/assets/style.css><link rel=stylesheet href=https://junhyukso.github.io/style.css><link rel=apple-touch-icon-precomposed sizes=144x144 href=https://junhyukso.github.io/img/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=https://junhyukso.github.io/img/favicon.png><link href=https://junhyukso.github.io/assets/fonts/Inter-Italic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-Regular.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-Medium.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-MediumItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-Bold.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-BoldItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><meta name=twitter:card content="summary"><meta name=twitter:title content="[REVIEW]PatDNN: Achieving Real-Time DNN Execution on Mobile Devices with Pattern-based Weight Pruning"><meta name=twitter:description content="Pattern based Pruning을 적용한 가속 Framework인 PatDNN에 대해 알아봅시다."><meta property="og:title" content="[REVIEW]PatDNN: Achieving Real-Time DNN Execution on Mobile Devices with Pattern-based Weight Pruning"><meta property="og:description" content="Pattern based Pruning을 적용한 가속 Framework인 PatDNN에 대해 알아봅시다."><meta property="og:type" content="article"><meta property="og:url" content="https://junhyukso.github.io/post/patdnn/"><meta property="article:published_time" content="2021-01-02T21:40:20+09:00"><meta property="article:modified_time" content="2021-01-02T21:40:20+09:00"><meta property="og:site_name" content="Junhyuk So's Blog"></head><body><div class=container><header class=header><span class=header__inner><a href=/ class=logo style=text-decoration:none><span class=logo__mark><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg></span><span class=logo__text>Junhyuk So's Blog</span>
<span class=logo__cursor></span></a><span class=header__right><nav class=menu><ul class="menu__inner menu__inner--desktop"><li><a href=/about>About</a></li><li><a href=/archive>Archive</a></li><li><a href=/tags>Tags</a></li></ul><ul class="menu__inner menu__inner--mobile"><li><a href=/about>About</a></li><li><a href=/archive>Archive</a></li><li><a href=/tags>Tags</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></span><span class=theme-toggle><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M22 41C32.4934 41 41 32.4934 41 22 41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span></span></span></header><div class=content><div class=post><h1 class=post-title>[REVIEW]PatDNN: Achieving Real-Time DNN Execution on Mobile Devices with Pattern-based Weight Pruning</h1><div class=post-meta><span class=post-date>2021-01-02</span>
<span class=post-read-time>— 2 min read</span></div><figure class=post-cover><img src=https://junhyukso.github.io/img/post/patdnn/conver.png alt="[REVIEW]PatDNN: Achieving Real-Time DNN Execution on Mobile Devices with Pattern-based Weight Pruning"></figure><div class=post-content><h2>Table of Contents</h2><aside class=table-of-contents><nav id=TableOfContents><ul><li><a href=#pruning>Pruning</a><ul><li><a href=#unstructured-pruning>Unstructured Pruning</a></li><li><a href=#structured-pruning>Structured Pruning</a></li></ul></li><li><a href=#pattern-based-pruning>Pattern based Pruning</a><ul><li><a href=#kernel-pattern-pruning>Kernel Pattern Pruning</a></li><li><a href=#connectivity-pruning>Connectivity Pruning</a></li><li><a href=#expreiment-result>Expreiment Result</a></li></ul></li><li><a href=#reference>Reference</a></li></ul></nav></aside><h2 id=pruning>Pruning</h2><p><img src=/img/post/patdnn/fig2.png alt=Pruning>
Pruning은 딥러닝 모델에서 <strong>특정 Weight들을 0으로만들거나, 아예 제거시키는 기법</strong>입니다.<br>이렇게 하게되면 <strong>정확도를 조금만 떨어트리거나 혹은 심지어 향상시키면서</strong>, <strong>모델의 사이즈나 추론속도를 빠르게 만들 수 있습니다.</strong></p><h3 id=unstructured-pruning>Unstructured Pruning</h3><p>Unstructured Pruning이란 Fig 2.(a)와 같이 <strong>element-wise</strong>하게 Pruning 하는 방법입니다.<br>이러면 <strong>낮은 Accuracy Drop</strong>과 **상대적으로 높은 Pruning Rate(Sparsity)**는 얻을 수 있으나, 매우 높은 Sparsity가 아닌 이상 <strong>추론속도를 향상시키기가 실질적으로 어렵</strong>습니다.<br>왜냐하면 딥러닝 연산은 대부분 <strong>행렬곱</strong> 연산으로 수행되는데, <strong>Sparse 행렬곱</strong>의 경우는 **Sparsity가 약 8~90%**정도는 되어야만 <strong>가속 효과</strong>가 나타나기 때문입니다. <strong>낮은 Sparsity</strong>에서는 Sparse행렬곱의 변환오버헤드 때문에 <strong>오히려 느립니다.</strong></p><h3 id=structured-pruning>Structured Pruning</h3><p>Structured Pruning은 Fig2.(b)와 같이, 일정 Group을 지정하여 <strong>Group을 통째로 Prune</strong>하는 방법입니다.<br>이때 Group은 <strong>HW아키텍쳐의 레인</strong>에 맞춘 사이즈라던가, 심지어 <strong>Conv의 필터/채널 전체</strong>를 제거할수도 있습니다.<br>특히 <strong>CNN</strong>의 경우는 필터/채널을 제거하게 되면 <strong>추론속도의 향상을 바로 담보할 수 있으므로</strong>, 필터/채널 자체를 제거하는 방법을 주로 사용합니다.<br>그러나, 이러한 방법은 <strong>Accuracy Drop이 크다</strong>는 단점이 있습니다.</p><h2 id=pattern-based-pruning>Pattern based Pruning</h2><p><img src=/img/post/patdnn/table2.png alt="Pruning performace">
정리하면, <strong>Unstructured Pruning</strong> 는 <strong>Acc Drop이 낮지만 가속을 기대하기가 어렵고</strong>,<br><strong>Structured Pruning</strong>은 <strong>Acc Drop이 크지만 높은 가속</strong>을 기대할 수 있습니다.<br><strong>Pattern based Pruning</strong>은 이러한 두 Pruning기법의 장점을 모두 챙기는, <strong>중간지점</strong>으로 제시되었습니다.</p><h3 id=kernel-pattern-pruning>Kernel Pattern Pruning</h3><p><img src=/img/post/patdnn/fig3.png alt="Pattern Pruning">
다음과 같은 Step들로 수행됩니다.</p><ul><li>모델을 <strong>우선 Pretrain</strong>합니다.</li><li>Conv의 <strong>한 Kernel</strong>에서 <strong>고정된 갯수의 수의 Weight</strong>만 남기고 Pruning 합니다.<ul><li>논문에서는 **4개의 Weight를 남길때 가장 성능이 좋았다고 합니다.</li></ul></li><li><strong>3x3Conv</strong>고, 한 커널당 <strong>4개</strong>의 weight를 살렸다 가정하면 <strong>8C3개</strong>의 경우의 수가 있습니다.<ul><li>커널의 <strong>가운데는 중요한 정보</strong>를 담고 있기때문에 Pruning 되어선 안됩니다. 따라서 9C4가 아닌 8C3입니다.</li></ul></li><li>모델의 전체 Kernel들을 탐색하며, <strong>가장 많이 등장하는 Top-K개의 커널을 조사</strong>합니다.</li><li>가장 많이 등장한 <strong>K개의 커널만 살리고</strong>, 나머지는 <strong>제거</strong>(Connectivity Pruning,후술)합니다.<ul><li>논문에서는 8개 Kernel을 살릴때 성능,속도가 최적이라고 합니다.</li></ul></li><li>떨어진 정확도를 복구하기 위해 fine tuning을 진행합니다.</li></ul><h3 id=connectivity-pruning>Connectivity Pruning</h3><p><img src=/img/post/patdnn/fig4.png alt="Connection Pruning">
Connectivity Pruning은 Convolution에서 <strong>Input Channel과 Output Channel의 연결을 끊는것</strong>, 즉 <strong>매칭되는 Filter를 제거하는 것</strong>입니다.<br><strong>Kernel Pattern Pruning에서 살리는 Kernel 이외는 제거하여 Connection을 끊습니다.</strong></p><h3 id=expreiment-result>Expreiment Result</h3><p><img src=/img/post/patdnn/table3.png alt="Accuracy Comparison">
이러한 Pruning 기법을 <strong>VGG16, ResNet50</strong>을 적용한결과 <strong>정확도가 오히려 상승</strong>하는 결과를 보였습니다.<br>또한, Pattern에 맞춰 <strong>최적화된 Convolution Code</strong>를 작성할 수도 있습니다.<br><strong>Inference code Optimization</strong>과 다른 여러가지 가속 기법(Filter kernel reordering, Load redundancy elimination, GA based parameter auto tuning)등을 적용하여, TFLite나 MNN에 비해 <strong>큰 가속</strong>을 보였습니다.
<img src=/img/post/patdnn/fig12.png alt="Performance Comparison"></p><h2 id=reference>Reference</h2><p><a href=https://arxiv.org/pdf/2001.00138.pdf>https://arxiv.org/pdf/2001.00138.pdf</a></p></div><div class=pagination><div class=pagination__title><span class=pagination__title-h>Read other posts</span><hr></div><div class=pagination__buttons><span class="button previous"><a href=https://junhyukso.github.io/post/repvgg/><span class=button__icon>←</span>
<span class=button__text>[REVIEW] RepVGG:Making VGG-style ConvNets Great Again</span></a></span>
<span class="button next"><a href=https://junhyukso.github.io/post/bn_v1/><span class=button__text>Batch Normalization 정리</span>
<span class=button__icon>→</span></a></span></div></div><script src=https://utteranc.es/client.js repo=junhyukso/junhyukso.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div><footer class=footer><div class=footer__inner><a href=/ class=logo style=text-decoration:none><span class=logo__mark><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg></span><span class=logo__text>Junhyuk So's Blog</span>
<span class=logo__cursor></span></a><div class=copyright><span>© 2021 Powered by
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a></span>
<span>Theme created by
<a href=https://twitter.com/panr target=_blank rel=noopener>panr</a></span></div></div></footer><script src=https://junhyukso.github.io/assets/main.js></script><script src=https://junhyukso.github.io/assets/prism.js></script></div></body></html>