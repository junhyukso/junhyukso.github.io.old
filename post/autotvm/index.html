<!doctype html><html lang=ko><head><title>[Review] Learning to Optimize Tensor Program ::
Junhyuk So's Blog</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Intro   Kernel들은, 성능에 영향을 미치는 수많은 Design space들이 있을 수 있습니다.
 Loop Order Loop Unrolling Tiling Size Local word size &amp;hellip;    이러한 모든 조합을 고려한 경우의 수는, 보통 Billon단위로, Auto Tuner제작시 이러한 Design Space를 모두 탐색하는 것은 거의 불가능합니다.
  그렇다고 해서, 커널의 성능을 저러한 변수들로 수식적으로 모델링하는 것도 너무 어렵습니다.
  -&amp;gt;따라서, TVM측에서는 이를 머신러닝에 기반한 성능예측기로, Search space를 획기적으로 좁히고자 하였습니다."><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://junhyukso.github.io/post/autotvm/><script async src="https://www.googletagmanager.com/gtag/js?id=G-Q6LJX3GCJZ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-Q6LJX3GCJZ');</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]}};</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><link rel=stylesheet href=https://junhyukso.github.io/assets/style.css><link rel=stylesheet href=https://junhyukso.github.io/style.css><link rel=apple-touch-icon-precomposed sizes=144x144 href=https://junhyukso.github.io/img/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=https://junhyukso.github.io/img/favicon.png><link href=https://junhyukso.github.io/assets/fonts/Inter-Italic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-Regular.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-Medium.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-MediumItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-Bold.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=https://junhyukso.github.io/assets/fonts/Inter-BoldItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><meta name=twitter:card content="summary"><meta name=twitter:title content="[Review] Learning to Optimize Tensor Program"><meta name=twitter:description content="TVM의 머신러닝 기반 오토튜너인 AutoTVM에 대해 알아봅시다."><meta property="og:title" content="[Review] Learning to Optimize Tensor Program"><meta property="og:description" content="TVM의 머신러닝 기반 오토튜너인 AutoTVM에 대해 알아봅시다."><meta property="og:type" content="article"><meta property="og:url" content="https://junhyukso.github.io/post/autotvm/"><meta property="article:published_time" content="2021-03-23T00:43:37+09:00"><meta property="article:modified_time" content="2021-03-23T00:43:37+09:00"><meta property="og:site_name" content="Junhyuk So's Blog"></head><body><div class=container><header class=header><span class=header__inner><a href=/ class=logo style=text-decoration:none><span class=logo__mark><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg></span><span class=logo__text>Junhyuk So's Blog</span>
<span class=logo__cursor></span></a><span class=header__right><nav class=menu><ul class="menu__inner menu__inner--desktop"><li><a href=/about>About</a></li><li><a href=/archive>Archive</a></li><li><a href=/tags>Tags</a></li></ul><ul class="menu__inner menu__inner--mobile"><li><a href=/about>About</a></li><li><a href=/archive>Archive</a></li><li><a href=/tags>Tags</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></span><span class=theme-toggle><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M22 41C32.4934 41 41 32.4934 41 22 41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span></span></span></header><div class=content><div class=post><h1 class=post-title>[Review] Learning to Optimize Tensor Program</h1><div class=post-meta><span class=post-date>2021-03-23</span>
<span class=post-read-time>— 2 min read</span></div><span class=post-tags><a href=https://junhyukso.github.io/tags/deeplearning/>#DeepLearning</a>&nbsp;
<a href=https://junhyukso.github.io/tags/tvm/>#TVM</a>&nbsp;
<a href=https://junhyukso.github.io/tags/compiler/>#Compiler</a>&nbsp;</span><figure class=post-cover><img src=https://junhyukso.github.io/img/post/autotvm/overview.png alt="[Review] Learning to Optimize Tensor Program"></figure><div class=post-content><h2>Table of Contents</h2><aside class=table-of-contents><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#system-overview>System Overview</a></li><li><a href=#tuning-algorithm>Tuning Algorithm</a></li><li><a href=#ml-model>ML Model</a></li><li><a href=#distributed-rpc>Distributed RPC</a></li><li><a href=#performace>Performace</a></li></ul></nav></aside><h2 id=intro>Intro</h2><p><img src=/img/post/autotvm/schedule.png alt=schedule></p><ul><li><p>Kernel들은, 성능에 영향을 미치는 수많은 Design space들이 있을 수 있습니다.</p><ul><li>Loop Order</li><li>Loop Unrolling</li><li>Tiling Size</li><li>Local word size</li><li>&mldr;</li></ul></li><li><p>이러한 모든 조합을 고려한 경우의 수는, 보통 Billon단위로, Auto Tuner제작시 이러한 Design Space를 모두 탐색하는 것은 거의 불가능합니다.</p></li><li><p>그렇다고 해서, 커널의 성능을 저러한 변수들로 <strong>수식적으로 모델링</strong>하는 것도 너무 어렵습니다.</p></li><li><p>->따라서, TVM측에서는 이를 머신러닝에 기반한 성능예측기로, Search space를 획기적으로 좁히고자 하였습니다.</p></li></ul><h2 id=system-overview>System Overview</h2><p><img src=/img/post/autotvm/overview.png alt=overview></p><ul><li>Auto TVM 시스템의 간단한 작동개요는 다음과 같습니다.<ul><li>AutoTVM시스템은 입력으로 Neural Net Graph를, 출력으로 Optimized Backend Kernel을 출력합니다.</li><li>우선 Tuning Algorithm내부의 ML Model이, Scedule Space에서 유망해 보이는 몇가지 후보를 추론하여 제공합니다.<ul><li>여기서 Scedule이란 , Tiling Size나 Loop Unrolling Factor같은 Search space들을 말합니다.</li></ul></li><li>TVM이 헤당 Schedule을 받아, 그에 맞는 Backend Kernel을 생성합니다.</li><li>이를 실제 하드웨어에 구동시켜, 실제 Latency(Cost)를 측정합니다.</li><li>측정된 실제 데이터로, ML Model을 train 시킵니다.</li><li><strong>이러한 루프를 계속 반복하여, Optimized된 Kernel을 찾게 됩니다.</strong></li></ul></li></ul><h2 id=tuning-algorithm>Tuning Algorithm</h2><p><img src=/img/post/autotvm/algorithm.png alt=algorithm></p><ul><li>Tuning Algorithm에 대해 더 자세히 살펴보도록 하겠습니다.</li><li>우선 Massive Parallel Simulated Anealing Algorithm을 통해 ML모델(f')을 사용하여 유망한 후보 Q를 추리게 됩니다.<ul><li>위 알고리즘을 사용하는 이유는, ML Model을 사용하더라도 Design space가 너무 커 유망한 후보 Top K개를 추리기 어렵기 때문입니다.</li></ul></li><li>Q에서 Cost를 Minimize시키면서도, 조합의 Diversity를 최대로 하는 조합 S를 Epsilon Greedy Algorithm을 통해 추립니다.</li><li>S에 약간의 랜덤성을 부여한 후, 이를 실제 기기(f)에서 측정하여, My Dataset에 데이터를 추가합니다.</li><li>얻어진 My Dataset으로, ML Model을 retrain시킵니다.</li><li>이를 Max N Trial까지 루프돌며 반복하게 됩니다.</li><li>알고리즙의 출력으로, 찾아진 S중 cost가 가장 낮았던 S&rsquo;를 출력하게 됩니다.</li></ul><h2 id=ml-model>ML Model</h2><ul><li>결국 위 알고리즘에서 ML Model을 사용하는 이유는, 시간이 많이 소요되는 과정(Compile -> Evaluation from real HW)을 피하고자 함에 있습니다.<ul><li>따라서, ML Model의 retrain + inference시간이, 실제 기기에서의 테스팅 시간에 비해 매우 낮아야 의미있는 모델일 것입니다.</li></ul></li><li>AutoTVM의 저자들은, XGBoost기반 모델을 사용하였습니다.<ul><li>XGBoost의 inference time은 약 0.67ms로, 실제 기기에서 커널 수행시간 보다 약 1000배 이상 빨랐다고 합니다.</li><li>저자들은 DL기반의, TreeGRU모델또한 사용해 보았으나 Acc는 비슷한데에 비해 Latency만 커, XGBoost를 사용했다고 합니다.</li></ul></li><li>학습시 Loss functing으로, Regression Loss가 아닌 Rank Loss를 사용했습니다.<ul><li>ML Model의 역할은 유망한 후보 Q를 뽑는 목적이므로, 커널의 시간을 정확히 맞추긴 보단 상대적인 우위만 맞추면 됩니다.
<img src=/img/post/autotvm/rank_loss.png alt="Rank Loss"></li></ul></li></ul><h2 id=distributed-rpc>Distributed RPC</h2><p><img src=/img/post/autotvm/dRPC.png alt=DRPC></p><ul><li>Tuning Algorithm에서 볼 수 있듯, 결국 실제 디바이스에서 커널시간을 측정하는 과정이 많이 필요합니다.</li><li>하지만, 이러한 과정은 매우 귀찮고 시간이 오래걸릴 수 있습니다.</li><li>TVM에서는 RPC를 사용하여, Host에서 Kernel만 Server로 전송하게 되면, 서버가 기기와 통신해 컴파일된 코드를 보내고, 기기에서 수행시간을 측정해 Host로 보내주는 편리한 Interface를 구축해 이 문제를 해결했습니다.</li></ul><h2 id=performace>Performace</h2><p><img src=/img/post/autotvm/result.png alt=result></p><ul><li>(2019년 기준으로) Server, Mobile, GPU, CPU모두에 대해 TVM이 가장 우수한 성능을 보여주었습니다.</li></ul></div><div class=pagination><div class=pagination__title><span class=pagination__title-h>Read other posts</span><hr></div><div class=pagination__buttons><span class="button next"><a href=https://junhyukso.github.io/post/repvgg/><span class=button__text>[REVIEW] RepVGG:Making VGG-style ConvNets Great Again</span>
<span class=button__icon>→</span></a></span></div></div><script src=https://utteranc.es/client.js repo=junhyukso/junhyukso.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div><footer class=footer><div class=footer__inner><a href=/ class=logo style=text-decoration:none><span class=logo__mark><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg></span><span class=logo__text>Junhyuk So's Blog</span>
<span class=logo__cursor></span></a><div class=copyright><span>© 2021 Powered by
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a></span>
<span>Theme created by
<a href=https://twitter.com/panr target=_blank rel=noopener>panr</a></span></div></div></footer><script src=https://junhyukso.github.io/assets/main.js></script><script src=https://junhyukso.github.io/assets/prism.js></script></div></body></html>